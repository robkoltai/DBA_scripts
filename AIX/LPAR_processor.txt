Definitions

A virtual processor is a unit of a virtual processor resource that is allocated to a partition or
virtual machine. PowerVM hypervisor can map a whole physical processor core, or it can
create a time slice of a physical processor core.

Entitlement is the capacity that an SPLPAR is ensured to get its share from the shared pool.
Uncapped mode allows a partition to receive excess cycles when there are free (unused)
cycles in the system.

SHOULD BE CALLED SPREADING FACTOR
VP>Entitlement
2VP and 2,5 Entitlement does not work


- file:///C:/Users/lenovo/Downloads/IBM%20PowerVM%20CPU%20Virtualization.pdf page 11
An SPLPAR has two virtual
processors. This means that the
assigned processing units must be
somewhere between 0.2 and 2. The
maximum processing units that the
SPLPAR can utilize is two.


- VP should not exceed shared pool capacity
The number of virtual processors in each LPAR in the system ought not to exceed the number
of cores available in the system (central electronic complex (CEC)/framework). Or, if the
partition is defined to run in a specific virtual shared processor pool, the number of virtual
processors ought not to exceed the maximum that is defined for the specific virtual shared
processor pool. Having more virtual processors that are configured than can be running at a
single point in time does not provide any additional performance benefit and can cause more
context switches of the virtual processors, which reduces performance.


- Sum Entintlement close to processor pool capacity, but cannot exceed it
	https://www.redbooks.ibm.com/redbooks/pdfs/sg248171.pdf
Entitlement also determines the number of SPLPARs that can be configured for a shared
processor pool. The sum of the entitlement of all the SPLPARs cannot exceed the number of
physical cores that are configured in a shared pool.

	At the same time, keeping entitlement low when there is capacity in the shared pool is not
always a preferred practice. Unless the partitions are frequently idle, or there is a plan to add
more partitions, the preferred practice is that the sum of the entitlement of all the SPLPARs
configured is close to the capacity in the shared pool. Entitlement cycles are guaranteed, so
when a partition is using its entitlement cycles, the partition is not preempted; however, a
partition can be preempted when it is dispatched to use excess cycles. Following this
preferred practice allows the hypervisor to optimize the affinity of the partitionâ€™s memory and
processor cores and also reduces unnecessary preemptions of the virtual processors.

- Entitlement should be close to real consumption
	- If undersized hypervisor may dispatch the same core for 2 lpars, which do not fit into that one core
	https://www.redbooks.ibm.com/redbooks/pdfs/sg248171.pdf
	Etitlement also affects the choice of memory and processors that are assigned by the
hypervisor for the partition. The hypervisor uses the entitlement value as a guide to the
amount of CPU that a partition consumes. If the entitlement is undersized, performance can
be adversely affected, for example, if there are four cores per processor chip and two
partitions are consistently consuming about 3.5 processors of CPU capacity. If the partitions
are undersized with four virtual processors and 2.0 entitlement (that is, entitlement is set
below normal usage levels), the hypervisor may allocate both of the partitions on the same
processor chip, as the entitlement of 2.0 allows two partitions to fit into a 4-core processor
chip. If both partitions consistently consume 3.5 processors worth of capacity, the hypervisor
is forced to dispatch some of the virtual processors on chips that do not contain memory that
is associated with the partitions. If the partitions were configured with an entitled capacity of
3.5 instead of 2.0, the hypervisor places each partition on its own processor chip to ensure
that there is sufficient processor capacity for each partition. This improves the locality,
resulting in better performance


- Entitlement should be average and the peak addressed by uncapped capacity
The aggregate entitlement (minimum or wanted processor) capacity of all LPARs in a system
is a factor in the number of LPARs that can be allocated. The minimum entitlement is what is
needed to boot the LPARs; however, the wanted entitlement is what an LPAR gets if there are
enough resources available in the system. The preferred practice for LPAR entitlement is to
match the entitlement capacity to average usage and let the peak be addressed by more
uncapped capacity.


PURR
SPURR
https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Power+Systems/page/CPU+frequency+monitoring+using+lparstat


Statistics meaning
https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/com.ibm.aix.prftools/processor_stat.htm


CPU and throughput
http://ksun-oracle.blogspot.hu/2015/04/ibm-aix-power7-cpu-usage-and-throughput.html

Szia, DÃ¡vid!
                Ez az eltÃ©rÃ©s nem anomÃ¡lia, egyszerÅ±en mÃ¡s van az Ã¡brÃ¡kon:

                RÃ¶viden:
-	LPAR2RRD: 
o	Fizikai CPU (PCPU) kiosztÃ¡st mutatja: az LPAR egy adott idÅ‘szakban a hypervisor mennyi fizikai CPU core-t rendelt az LPAR-hoz: gyakorlatilag ennyi PCPU van bedugva a virtuÃ¡lis gÃ©pbe
-	NMON: 
o	â€Câ€: alapbÃ³l OS szemszÃ¶gbÅ‘l, azaz Logikai CPU (LCPU) kihasznÃ¡ltsÃ¡got mutat 
ï‚§	SimÃ¡n lehet, hogy nem hasznÃ¡ljuk azt a CPU-t OS oldalon, ami rendelkezÃ©sre Ã¡ll (mint ahogy a fizikai gÃ©pben sem hasznÃ¡ljuk mindig 100%-on a CPU-kat)
o	â€tâ€: a CPU fogyasztÃ¡s itt is PCPU, de ez mÃ¡r a PCPU-erÅ‘ fogyasztÃ¡sa: az adott processz egy Core mekkora szÃ¡mÃ­tÃ¡si kapacitÃ¡sÃ¡t vette igÃ©nybe. 
ï‚§	Ennek a maximum Ã©rtÃ©ke az Ã©ppen hasznÃ¡lt SMT mÃ³d Ã©rtÃ©ke: SMT1-ben ez a COre erejÃ©nek max 30-35% lehet! Azaz, ha egy process 31.9%-ot fogyaszt, akkor az adott Core-t gyakorlatilag teljesen kihajtja! 

                Hosszan:
-	LPAR2RRD: 
o	A Fizikai CPU (PCPU) kiosztÃ¡st mutatja: azt, hogy idÅ‘arÃ¡nyosan mennyi CPU-t kapott az LPAR. Ha ez mondjuk 13, akkor egy mÃ¡sodperc alatt Ã¡tlagosan 13 db fizikai CPU Core lett kiosztva az LPARnak.
o	EbbÅ‘l a szempontbÃ³l nem szÃ¡mÃ­t, hogy SMT1-ben vagy SMT8-ban hasznÃ¡lÃ³dik kÃ¶zben a CPU. Az Ã¡brÃ¡zolt esetben SMT2-ben hasznÃ¡ljuk, de az nincs kiÃ¼tve, mÃ©g egy csomÃ³ szÃ¡mÃ­tÃ¡st el tudna vÃ©gezni a rendszer a megkapott PCPU
-	Nmon:
o	Tud Logikai Ã©s Fizikai CPU-kat is mutatni
o	AlapbÃ³l az OS szemszÃ¶gÃ©bÅ‘l lÃ¡tott, Ãºn. Logikai CPU (LCPU) hasznÃ¡latot mutatja
o	a â€Câ€-n lÃ¡tszanak a leglÃ©nyegesebb Ã¶sszefoglalÃ³ adatok mindkÃ©t esetre
ï‚§	A felsÅ‘ sorban 
â€¢	az â€EntitledCPU=â€ azt mutatja, hogy mennyi CPU-t kap meg mindenkÃ©pp az LPAR (amibÅ‘l aztÃ¡n adakozhat, ha akar)
â€¢	A â€UsedCPU=â€ azt mutatja, hogy valÃ³jÃ¡ban mennyi PCPU lett kiosztva/elhasznÃ¡lva az LPAR Ã¡ltal
o	Ha az LPAR-nak nem kell az eredetileg neki kiosztott PCPU , Ã©s ezÃ©rt visszaadja a kÃ¶zÃ¶sbe, akkor a UsedCPU kisebb, mint az EntitledCPU. 
o	Ha az LPAR mÃ©g igÃ©nyelt volna tÃ¶bb PCPU-t, Ã©s volt is szabadon, ezÃ©rt kapott is, akkor a UsedCPU nagyobb, mint az EntitledCPU
ï‚§	Minden LCPU-hoz tartozik egy â€oszlopâ€ a grafikonon, 
â€¢	egy sorban 64 LCPU lÃ¡tszik
â€¢	mivel nektek 128 LCPU van, ezÃ©rt kÃ©t sor kell
â€¢	Amikor 24 VCPU-val mentetek, akkor 192 LCPU-tok volt, ezÃ©rt 3 sor kellett
o	Ã‰s maikor elvettÃ©tek tÅ‘le a 24-bÅ‘l 8-at, nem pont az utolsÃ³ 8 VCPU-t vette el a Hypervisor, ezÃ©rt volt olyan is, hogy a 16-bÃ³l az egyik VCPU a harmadik sorban volt Ã¡brÃ¡zolva
ï‚§	Az elsÅ‘ 64db CPU-t mutatÃ³ grafikon rÃ©szlet jobb szÃ©lÃ©n van egy â€mindent Ã¶sszefoglalÃ³â€ rÃ©szlet, az â€Avg=LPâ€, ami az egÃ©sz LPAR-ra aggregÃ¡lt Ã©rtÃ©keket mutatja
â€¢	Az â€Lâ€ a Logikai CPU hasznÃ¡latot mutatja, azaz hogy az Ã¶sszes threadet figyelembe vÃ©ve a â€faliÃ³raâ€ szerint mennyire volt hasznÃ¡lva az Ã¶sszes LCPU
â€¢	A â€Pâ€ pedig a fizikai CPU (Physical CPU, PCPU) kihasznÃ¡ltsÃ¡gÃ¡t mutatja
â€¢	Itt az Ã¡ltalad kÃ¼ldÃ¶tt kÃ©pen jÃ³l lÃ¡tszik, hogy 
 
o	bÃ¡r 13.369 PCPU-t kapott meg az LPAR, 
o	ebbÅ‘l LCPU szintjÃ©n valahol 5-15% kÃ¶zt van a hasznÃ¡lat mÃ©rtÃ©ke (csak a 10%-ig Ã©r fel a grafikon), vagyis az OS szintÅ± â€Idleâ€ kb. 85% lenne
o	a megkapott PCPU-kban rejlÅ‘ szÃ¡mÃ­tÃ¡si kapacitÃ¡s kihasznÃ¡ltsÃ¡ga pedig valÃ³jÃ¡ban kb. 35-45% kÃ¶zt van (ez alig tÃ¶bb, mint amit SMT1 mÃ³dban tudna a rendszer, egy gyengÃ©n kihasznÃ¡lt SMT2 hasznÃ¡latot lÃ¡tunk)
o	sajnos igazÃ¡bÃ³l nem tudom, hogy pontosan a â€Barâ€ grafikon rajzolÃ¡sÃ¡nÃ¡l kerekÃ­t vagy vÃ¡g az nmon, de mivel ez egy hozzÃ¡vetÅ‘leges Ã©rtÃ©k, ezÃ©rt kb. mindegy is
o	a â€câ€ grafikon ugyanezeket mutatja, de sajnos a 128 LCPU miatt az aljÃ¡n lÃ©vÅ‘ Ã¶sszefoglalÃ³ nem lÃ¡tszik, csak ha nagyon lekicsinyÃ­ted a betÅ±mÃ©retet: 
â”Œâ”€topas_nmonâ”€â”€v=Verbose-hintsâ”€â”€â”€â”€Host=dwh-pdw-barâ”€â”€â”€â”€Refresh=2 secsâ”€â”€â”€07:24.42â”€â”€â”
â”‚ CPU-Utilisation-Small-View â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€EntitledCPU= 16.00 UsedCPU= 14.298â”€â”€â”€â”€â”€â”€â”‚
â”‚Logical  CPUs              0----------25-----------50----------75----------100 â”‚
â”‚CPU User%  Sys% Wait% Idle%|           |            |           |            | â”‚
â”‚  0  67.5   4.5  17.0  11.0|UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUssWWWWWWWW    > | â”‚
â”‚  1  56.5   1.0  20.0  22.5|UUUUUUUUUUUUUUUUUUUUUUUUUUUUWWWWWWWWWW      >    | â”‚
â”‚  2  32.5   1.5  14.5  51.5|UUUUUUUUUUUUUUUUWWWWWWW                    >     | â”‚
â”‚  3  35.0   0.5   8.5  56.0|UUUUUUUUUUUUUUUUUWWWW                          > | â”‚
â”‚  4   0.0   0.0   0.0 100.0|     >                                           | â”‚
â”‚  5   0.0   0.0   0.0 100.0|     >                                           | â”‚
â”‚  6   0.0   0.0   0.0 100.0|       >                                         | â”‚
â”‚  7   0.0   0.0   0.0 100.0|        >                                        | â”‚
â€¦
â”‚127   0.0   0.0   0.0 100.0|        >                                        | â”‚
â”‚EntitleCapacity/VirtualCPU +-----------|------------|-----------|------------+ â”‚
â”‚ EC  47.4   3.1   1.9  37.0|UUUUUUUUUUUUUUUUUUUUUUUsiiiiiiiiiiiiiiiiii-------| â”‚
â”‚ VP  47.4   3.1   1.9  37.0|UUUUUUUUUUUUUUUUUUUUUUUsiiiiiiiiiiiiiiiiii-------| â”‚
â”‚EC=  89.4%  VP=  89.4%     +--No Cap---|------------|-----------100% VP=16CPU+ â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
ï‚§	A fejlÃ©cben itt is lÃ¡tszik az EntitledCPU Ã©s a UsedCPU
ï‚§	Itt a sorok tartoznak az egyes LCPU-khoz
ï‚§	Az aljÃ¡n pedig az Ã¶sszefoglalÃ³, a â€EntitleCapacity/VirtualCPUâ€ rÃ©sz:
â€¢	EC: A valÃ³jÃ¡ban kiosztott PCPU milyen arÃ¡nyban van felhasznÃ¡lva az OS Ã¡ltal:
o	U- User, s- System, W-waitio, i-Idle, 
o	A â€-â€ â€“ az el nem hasznÃ¡lt / kÃ¶zÃ¶sbe adott rÃ©szt jelÃ¶li
ï‚§	Ha az LPAR kap plusz PCPU erÅ‘forrÃ¡st az eredeti EntiledCPU felett, akkor a â€-â€ nem szokott megjelenni, vagy csak 1db van belÅ‘le
â€¢	VP: Az Ã¶sszes VCPU-ra vonatkozÃ³ felhasznÃ¡lÃ¡st mutatja.
o	Ha nem teljes idÅ‘ben vannak hasznÃ¡lva a VCPU-k, akkor ez a sor kisebb hasznÃ¡latot mutat, mint az EC
o	Pl. ha az LPARnak van 5db VCPU-ja, de csak 2.5 PCPU-t hasznÃ¡l, Ã©s a Hypervisor mind az 5 VCPU-ra tud adni PCPU-t, akkor a VP csÃ­k csak az 50%-ig fog elÃ©rni: ez arra utal, hogy ilyenkor az idÅ‘ felÃ©ben van az Ã¶sszes VCPU hasznÃ¡lva (1/2*5=2.5)
o	NÃ¡latok ekkor nem volt ilyen, ezÃ©rt a kÃ©t csÃ­k egyforma hosszÃº
ï‚§	Alul van mÃ©g nÃ©hÃ¡ny aggregÃ¡ciÃ³:
â€¢	Jobb szÃ©len: VP=16CPU: HÃ¡ny db VCPU van az LPAR-ban
â€¢	Kicsit balrÃ¡bb lehetne egy â€Foldedâ€ szÃ¡m, ami az â€eltakartâ€ VCPU-kat mutatja: ezekre a Hypervisor Ã©s az OS egyÃ¼tt kimondta, hogy nem akar, vagy nem tud PCPU-t tenni 
o	ha a Folding mechanizmus nem lenne, akkor egy terheletlen LPAR-nak is ugyanannyi PCPU-t kellene kiosztani, amennyi a teljesen leterhelt esethez kell
â€¢	â€EC=â€: UsedCPU/EntitledCPU
â€¢	â€VP=â€: UsedCPU/VP  (a jobb szÃ©len lÃ©vÅ‘ VP= VCPU szÃ¡m)
o	Van mÃ©g egy â€Long Term CPUâ€ grafikon is (â€lâ€, kis L betÅ±), aminÃ©l az X tengely az idÅ‘, az Y tengely a CPU hasznÃ¡lat
ï‚§	Ennek kell egy kis idÅ‘, amÃ­g magÃ¡ra talÃ¡l, ezalatt nÃ©ha kiÃ­rja, hogy RESCALING, nÃ©ha nem, de csinÃ¡lja ğŸ˜Š
o	Ã‰s hogy mindenbe belekavarjon, van egy â€#â€ gomb is, ami bizonyos helyeken az LCPU-t lecserÃ©li PCPU adatokra
ï‚§	â€lâ€-ben a grafikon azt mutatja, amit az LPAR2RRD (a kiosztott PCPU-kat)
â€¢	A fejlÃ©c nem vÃ¡ltozik
â€¢	de az â€UsWiâ€ karakterek helyett â€Pâ€-ket mutat a grafikon
ï‚§	â€câ€-ben a sorok az egyes szÃ¡lakra jutÃ³ PCPU felhasznÃ¡lÃ¡st mutatjÃ¡k 
â€¢	Ekkor a fejlÃ©c: â€PURR Statsâ€
â€¢	ez gyakorlatilag egy thread esetÃ©ben nem lehet nagyobb, mint 35%, tehÃ¡t nem kell megijedni, hogy milyen kicsik a szÃ¡mok
â€¢	pl. egyenletes SMT8 terhelÃ©skor minden thread 12.5% lenne
â€¢	SMT1-ben pedig kb. 30-35% van az elsÅ‘ szÃ¡lon, a tÃ¶bbi 0
â€¢	Mivel a â€EntitleCapacity/VirtualCPUâ€ rÃ©sz eddig is PCPU adatokat mutatott, ez nem vÃ¡ltozik.
ï‚§	A â€Câ€ grafikon 
â€¢	A fejlÃ©c nem vÃ¡ltozik
â€¢	Az â€UsWiâ€ betÅ±k nem vÃ¡ltoznak
â€¢	DE a grafikon a 100% mÃ¡r nem a faliÃ³ra szerinti erÅ‘forrÃ¡s foglalÃ¡st mutatja, hanem az adott threadre vÃ¡rhatÃ³ maximum fizikai erÅ‘forrÃ¡s Ã©rtÃ©ket.
â€¢	Ennek megfelelÅ‘en Ã¡ltalÃ¡ban magasabbak a csÃºcsok:
o	Amelyik process futni akar, az kb. 100%-ig feltolja a grafikont
o	A nem-100% azt jelzi, hogy arra a LCPU-ra nem kellett processzt Ã¼temezni (nem volt futÃ³kÃ©pes process)
â€¢	Mivel nem mond semmit, amibÅ‘l kiderÃ¼l, hogy LCPU vagy PCPU adatokat mutat, ezÃ©rt Ã©rdemes mellette a LongTerm CPU-t is elindÃ­tani, mert ott lÃ¡tszik, a P betÅ±zÃ©s.
o	A â€tâ€, azaz a Top Processes-ben a CPU a processzenkÃ©nti fizikai PCPU hasznÃ¡latot mutatja (PURR Ã©rtÃ©kek)
ï‚§	Ez SMT1-ben kb. 30-35% lehet (pl. a 31.9% egy kiÃ¼tÃ¶tt core-t jelent)
ï‚§	SMT8-ban pedig kb. 12-13% maximum egy-egy threadre (Ã­gy Ã¶sszesen 100% fizikai CPU erÅ‘t tudnak kihasznÃ¡lni)
ï‚§	Vagyis az SMT1-ben egy szÃ¡lra jutÃ³ szÃ¡mÃ­tÃ¡si teljesÃ­tmÃ©ny kb. 3x-osa az SMT8-ban egy szÃ¡lra jutÃ³ szÃ¡mÃ­tÃ¡si teljesÃ­tmÃ©nynek.

Ãœdv,
Havasi ZoltÃ¡n
senior adatbÃ¡zis szakÃ©rtÅ‘
